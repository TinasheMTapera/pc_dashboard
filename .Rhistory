shiny::runApp()
mydf
source('~/Dropbox/Drexel U/Computer Science/CS530/Project/NewDataSet.R', echo=TRUE)
mydf=Load_Data(file.choose)
mydf=Load_Data(file.choose())
mydf
mydf$couns_opinion
mydf$couns_opinion == ""
all(mydf$couns_opinion == "")
runApp()
?icon()
runApp()
runApp()
install.packages("shinycssloaders")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
Load_Data(file.choose())
f = file.choose()
#read in the dataset
#f = list.files("./data")[1]
dat = read.csv(f,fill=TRUE)
dat
dat = read.csv(f,fill=TRUE)
#special case
if(nrow(dat) < 2){
return()
}
#get survey questions
questions = dat[1,]%>%
t()%>%
as.character()
#remove junk rows from qualtrics
dat = dat[-c(1,2),]
dat = dat%>%
filter(Finished == "True")
dat
dat = read.csv(f,fill=TRUE)
#special case
if(nrow(dat) < 2){
return()
}
#get survey questions
questions = dat[1,]%>%
t()%>%
as.character()
#remove junk rows from qualtrics
dat = dat[-c(1,2),]
dat
runApp()
dat
mydf = Load_Data(f)
source('~/Dropbox/Drexel U/Computer Science/CS530/Project/NewDataSet.R', echo=TRUE)
mydf = Load_Data(f)
mydf
dat = read.csv(f,fill=TRUE)
#special case
if(nrow(dat) < 2){
return()
}
#get survey questions
questions = dat[1,]%>%
t()%>%
as.character()
#remove junk rows from qualtrics
dat = dat[-c(1,2),]
dat = dat%>%
filter(Finished == "True" | Finished == "TRUE")
dat
runApp()
runApp()
runApp()
runApp()
?renderDataTable()
?DT::renderDataTable
runApp()
runApp()
runApp()
shiny::runApp()
rsconnect::setAccountInfo(name='tinashemtapera', token='FBBC273D16CE422F115E8B91CED24A0C', secret='DlrxoZ1PwkHAsAFZrmMMFqJv3Zqt1V7JgKx9lDqo')
library(rsconnect)
rsconnect::deployApp()
ls()
source('~/GDriveDocs/DataScience/pc_dashboard/NewDataSet.R', echo=TRUE)
shiny::runApp()
install.packages("shinyjs")
install.packages("sentimentr")
install.packages("shinyjs")
shiny::runApp()
runApp()
install.packages("DT")
if (!require("pacman")) install.packages("pacman")
install.packages("pacman")
pacman::p_load(shiny,
DT,
rlang,
shinyjs,
shinythemes,
tidyverse,
lubridate,
scales,
viridis,
tidytext,
sentimentr,
tm,
topicmodels,
plotly)
install.packages("sentimentr")
library(sentimentr)
update.packages("glue")
library(sentimentr)
source('~/GDriveDocs/DataScience/pc_dashboard/NewDataSet.R', echo=TRUE)
newdat = Load_Data("./PCH Call Log_October 2, 2018_10.47.csv")
newdat
source('~/GDriveDocs/DataScience/pc_dashboard/TopicModelling.R', echo=TRUE)
TidyText(newdat$body)
newdat$body
TidyText(newdat)
newdat$couns_opinion
newdat$couns_opinion%>%
as_tibble()
newdat$couns_opinion%>%
as_tibble(Opinion = .)
newdat$couns_opinion%>%
as_tibble()%>%
rename(value = Opinion)
newdat$couns_opinion%>%
as_tibble()%>%
rename(Opinion=value)
newdat$couns_opinion%>%
as_tibble()%>%
rename(Opinion=value)%>%
mutate(i = rownames(.))
newdat$couns_opinion%>%TidyText()
pacman::p_load_current_gh("trinker/lexicon", "trinker/sentimentr")
devtools::install_github("trinker/sentimentr")
library(sentimentr)
install.packages("glue", type="source")
install.packages("glue", type = "source")
library(sentimentr)
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
mtcars
iris
iris%>%
arrange(-Sepal.Length)
?n_distinct()
iris%>%
dplyr::group_by(Species)%>%
n_distinct(10)
iris%>%
arrange(-Sepal.Length)
iris%>%
arrange(-Sepal.Length)%>%
group_by(Species)%>%
unique()
ls()
#function to compute LDA topic model
TidyLDA = function(dat, k=10){
corp = dat%>%
filter(body != "")%>%
TidyText()%>%
select(body)%>%
VectorSource()%>%
Corpus()
#dict = corp
corp = tm_map(corp, stemDocument)
#corp = tm_map(corp, stemCompletion, dictionary=dict, type = "first")
dtm = corp%>%
DocumentTermMatrix()
lda = LDA(dtm, k, control = list(seed = 1234))
tidy(lda, matrix = "beta")%>%
mutate(beta = ifelse(beta > quantile(beta, c(0.8))[1], beta, 0))%>%
group_by(term)%>%
mutate(m = mean(beta))%>%
print()
# mutate(term = factor(term),
#        topic = factor(topic))%>%
# arrange(term)%>%
# return()
}
TidyLDA(newdat)
TidyLDA(newdat)%>%View()
#function to compute LDA topic model
TidyLDA = function(dat, k=10){
corp = dat%>%
filter(body != "")%>%
TidyText()%>%
select(body)%>%
VectorSource()%>%
Corpus()
#dict = corp
corp = tm_map(corp, stemDocument)
#corp = tm_map(corp, stemCompletion, dictionary=dict, type = "first")
dtm = corp%>%
DocumentTermMatrix()
lda = LDA(dtm, k, control = list(seed = 1234))
tidy(lda, matrix = "beta")%>%
mutate(beta = ifelse(beta > quantile(beta, c(0.8))[1], beta, 0))%>%
group_by(term)%>%
mutate(m = mean(beta))%>%
arrange(-m, -beta, term)%>%
return()
# mutate(term = factor(term),
#        topic = factor(topic))%>%
# arrange(term)%>%
# return()
}
TidyLDA(newdat)%>%View()
templda = TidyLDA(newdat)
templda
templda%>%top_n(3)
templda%>%top_n(1)
templda%>%group_by(m)%>%top_n(1)
templda%>%ungroup()%>%group_by(m)%>%top_n(1)
templda%>%ungroup()%>%group_by(term)%>%nest()
templda%>%ungroup()%>%group_by(term)%>%nest()%>%slice(10)
templda%>%ungroup()%>%group_by(term)%>%nest%>%slice(10)
templda%>%ungroup()%>%group_by(term)%>%nest%>%slice(1:10)
templda%>%ungroup()%>%group_by(term)%>%nest%>%slice(1:10)%>%unnest()
#function to compute LDA topic model
TidyLDA = function(dat, k=10){
corp = dat%>%
filter(body != "")%>%
TidyText()%>%
select(body)%>%
VectorSource()%>%
Corpus()
#dict = corp
corp = tm_map(corp, stemDocument)
#corp = tm_map(corp, stemCompletion, dictionary=dict, type = "first")
dtm = corp%>%
DocumentTermMatrix()
lda = LDA(dtm, k, control = list(seed = 1234))
tidy(lda, matrix = "beta")%>%
mutate(beta = ifelse(beta > quantile(beta, c(0.8))[1], beta, 0))%>%
group_by(term)%>%
mutate(m = mean(beta))%>%
arrange(-m, -beta, term)%>%
nest()%>%
slice(1:10)%>%
unnest()%>%
return()
# mutate(term = factor(term),
#        topic = factor(topic))%>%
# arrange(term)%>%
# return()
}
TidyLDA(newdat)
runApp()
ll = TidyLDA(newdat)
lda = ll
lda$term = factor(lda$term,
levels(lda$term)[order(levels(lda$term), decreasing = TRUE)])
lda
#function to compute LDA topic model
TidyLDA = function(dat, k=10){
corp = dat%>%
filter(body != "")%>%
TidyText()%>%
select(body)%>%
VectorSource()%>%
Corpus()
#dict = corp
corp = tm_map(corp, stemDocument)
#corp = tm_map(corp, stemCompletion, dictionary=dict, type = "first")
dtm = corp%>%
DocumentTermMatrix()
lda = LDA(dtm, k, control = list(seed = 1234))
tidy(lda, matrix = "beta")%>%
mutate(beta = ifelse(beta > quantile(beta, c(0.8))[1], beta, 0))%>%
group_by(term)%>%
mutate(m = mean(beta))%>%
arrange(-m, -beta, term)%>%
nest()%>%
slice(1:10)%>%
unnest()%>%
mutate(term = factor(term),
topic = factor(topic))%>%
select(-m)%>%
return()
}
ll = TidyLDA(newdat)
ll
lda=ll
lda$term = factor(lda$term,
levels(lda$term)[order(levels(lda$term), decreasing = TRUE)])
runApp()
runApp()
raw = read.csv("./PCH Call Log_October 2, 2018_10.47.csv", fill=TRUE)
raw
dat = raw
#remove incomplete rows from qualtrics
dat = dat[-c(1,2),]
dat
dat = as.tibble(raw)
dat
dat = as.tibble(raw[-c(1:2),])
dat
read.csv("./PCH Call Log_October 2, 2018_10.47.csv", fill=TRUE)%>%
.[-c(1:2),]%>%
as.tibble()
dat = read.csv("./PCH Call Log_October 2, 2018_10.47.csv", fill=TRUE)%>%
.[-c(1:2),]%>%
as.tibble()
#remove incomplete rows from qualtrics
dat = dat%>%
filter(Finished == "True" | Finished == "TRUE")
dat%>%
mutate(call_start = paste0(
as.character(.$start_date), " ",
Add_Zero(.$start_time_1), ":",
Add_Zero(.$start_time_2), " ",
toupper(as.character(.$start_time_3))
))
dat%>%
mutate(call_start = paste0(
as.character(.$start_date), " ",
Add_Zero(.$start_time_1), ":",
Add_Zero(.$start_time_2), " ",
toupper(as.character(.$start_time_3))
))%>%View()
dat%>%
mutate(call_start = mdy_hm(paste0(
as.character(.$start_date), " ",
Add_Zero(.$start_time_1), ":",
Add_Zero(.$start_time_2), " ",
toupper(as.character(.$start_time_3)))))
dat%>%
mutate(call_start = mdy_hm(paste0(
as.character(.$start_date), " ",
Add_Zero(.$start_time_1), ":",
Add_Zero(.$start_time_2), " ",
toupper(as.character(.$start_time_3)))))
dat%>%
mutate(call_start = mdy_hm(paste0(
as.character(.$start_date), " ",
Add_Zero(.$start_time_1), ":",
Add_Zero(.$start_time_2), " ",
toupper(as.character(.$start_time_3)))))%>%View()
TZ = "America/New_York"
Sys.setenv(TZ="America/New_York")
dat%>%
mutate(call_start = mdy_hm(paste0(
as.character(.$start_date), " ",
Add_Zero(.$start_time_1), ":",
Add_Zero(.$start_time_2), " ",
toupper(as.character(.$start_time_3)))),
call_end = mdy_hm(paste0(
as.character(.$end), " ",
Add_Zero(.$end_time_1), ":",
Add_Zero(.$end_time_2), " ",
toupper(as.character(.$end_time_3)))))%>%
select(-c(start_date:end_time_3))
#read in the dataset
#f = list.files("./data")[1]
dat = read.csv(f,fill=TRUE)%>%
.[-c(1:2),]%>%
as.tibble()
f = "./PCH Call Log_October 2, 2018_10.47.csv"
#read in the dataset
#f = list.files("./data")[1]
dat = read.csv(f,fill=TRUE)%>%
.[-c(1:2),]%>%
as.tibble()
#remove incomplete rows from qualtrics
dat = dat%>%
filter(Finished == "True" | Finished == "TRUE")
#convert datetimes for call start and end
dat = dat%>%
mutate(call_start = mdy_hm(paste0(
as.character(.$start_date), " ",
Add_Zero(.$start_time_1), ":",
Add_Zero(.$start_time_2), " ",
toupper(as.character(.$start_time_3)))),
call_end = mdy_hm(paste0(
as.character(.$end), " ",
Add_Zero(.$end_time_1), ":",
Add_Zero(.$end_time_2), " ",
toupper(as.character(.$end_time_3)))))%>%
select(-c(start_date:end_time_3))
#read in the dataset
#f = list.files("./data")[1]
dat = read.csv(f,fill=TRUE)%>%
.[-c(1:2),]%>%
as.tibble()
#remove incomplete rows from qualtrics
dat = dat%>%
filter(Finished == "True" | Finished == "TRUE")
#convert datetimes for call start and end
dat = dat%>%
mutate(call_start = mdy_hm(paste0(
as.character(.$start_date), " ",
Add_Zero(.$start_time_1), ":",
Add_Zero(.$start_time_2), " ",
toupper(as.character(.$start_time_3)))),
call_end = mdy_hm(paste0(
as.character(.$end_date), " ",
Add_Zero(.$end_time_1), ":",
Add_Zero(.$end_time_2), " ",
toupper(as.character(.$end_time_3)))))%>%
select(-c(start_date:end_time_3))
dat
#record when log was submitted
dat = dat%>%
mutate(Recorded = ymd_hms(.$RecordedDate))%>%
select(-RecordedDate)
dat
#only take columns from relevant call info onwards
dat = dat%>%
select(primary:Recorded)
dat
dat$primary_issues
dat$referrals
dat$referrals%>%separate()
dat%>%separate(referrals)
?separate
names(dat)
dat%>%
mutate(body = as.character(body))
